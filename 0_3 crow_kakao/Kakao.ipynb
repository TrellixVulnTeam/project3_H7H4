{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f74531f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### 0\n",
      "#### 광고카페라라라\n",
      "바다 앞이라 뷰가 너무 좋아요~ 당근케이크도 맛있고 당근 착즙주스랑 잘어울려요! 나이별 컵홀더를 주시는것도 재미있어요!/5\n",
      "감성 카페? 뭐가 감성인지는 잘 모르겠으나 아무튼 요즘 말하는 전형적인 감성 카페임 ㅎ 카카오 맵 리뷰이벤트 하면 서비스가 있기때문에 이 막대한 리뷰작성 수를 보유하면서도 4점 후반대를 유지는게 아닐까?  솔직히 가격이 좀 비싸서 그렇지 뷰 좋고 맛도 어느정도 괜찮은 가게인건 맞으나 평점보고 눈 돌아가서 꼭 가야하는 곳으로 생각하는 오류는 범하지 마시길...../2\n",
      "위치가 좋아요. 시원한 바다 바로 앞이라 음료 시키고 감상하기에 딱인 곳. 당근케익은 너무 달고 빵은 살짝 떡처럼 꾸덕해서 제 입맛엔 안맞았고 당근쥬스는 그냥 당근쥬스에요. 가격도 좀 있어요. /4\n",
      "당근케이크 느끼하지 않고 맛있어요 !/5\n",
      "작년에 오고 또 왔어요! 당근주스도 맛있고, 세화 앞바다 풍경도 예쁜 카페입니다 :)/5\n",
      "에메랄드 바닷빛, 다양한 사진 스팟이 있어요!  구좌당근주스는 꼭 드셔보세요^^/5\n",
      "넘 예쁜 세화해변의 바다를 바라보며 그색에 취하고,그기억을 옆서에 담아 보낸다는~~♡/4\n",
      "카페 앞 바다가 너무 깨끗하고 예뻐서 뷰 맛집 당근주스는 100퍼 착즙이라서 그냥 인공적인 단맛이 아니고 당근의 단맛이 잘 느껴지는 맛이에요/5\n",
      "당근 디저트도 맛있었고 엽서로 그림 그리면 집으로 보내주신다고 해서 잠시 몰입했네요. 뷰도 좋고 여러모로 힐링되었습니다/5\n",
      "일단 뷰가 너무 좋고 당근이 엄청 크고 신선도도 느껴져요~~ 후후 /5\n",
      "뷰가 너무 이뻐서 한참을 있다가 갑니다! 뷰 맛집 인정! 야외테이블에서 드세요!!/5\n",
      "뷰도 좋고 케이크 맛있어용!!!! 고양이도 너무 귀여워요 한라봉차 맛있어요!/5\n",
      "밤바다 보러 나왔다가 카페에 들어오게 되었는데, 분위기도, 맛도, 전망도 너무 좋네요ㅎㅎ 힐링!! 바다가 보이는 스팟마다 포토존 마련도 되어있어서  맑은 날 낮에 오면 더 좋을듯(๑˃̵ᴗ˂̵๑)/5\n",
      "해변에서 경치 구경하며 즐기기 좋은 카페였습니다./5\n",
      "당근케이크는 너무 맛있는데 당근주스는 조금 달았어요. 경치가 너무 예쁘고, 엽서 주시는 것도 좋았어요~/5\n",
      "당근 케이크도 맛잇고 뷰도 넘 예뻐요!!/5\n",
      "바다가 너무예뻐요…당근맛집인줄몰랐는데 리뷰보니 담엔 당근주스 먹으러올래요,, 한라봉 냉차도 맛있어요 /5\n",
      "지나가다가 들어왔어용! 핫플인거 같아용 느린 우체통도 있어서 좋은 추억 쌓고 갑니당 ㅎㅎ/5\n",
      "세화 오면 카페라라라는 무조건 들려야하는 곳!  여기서 인생 ⭑당근케이크⭑를 먹었음••/5\n",
      "사랑은 연필로 쓰세요. 잎글(엽서)에 담아- 추억을 남기는 곳 @카페라라라 갈 때 가더라도 당근 케이크 정돈 괜찮잖아 진한 여운이 남습니다!!! (의식의 흐름에 따른 후기!! 황홀해서 그래요)/5\n",
      "뷰맛집!예쁜 우체통이 있어요! 당근케이크에 견과류도 많이 올려져있어요!/5\n",
      "제주 구좌에 오면 당근쥬스 한잔 마셔야 한다며... 올때마다 들르는 곳이예요~ 당근쥬스가 찌~인하고 정말 맛있어요!!  거기에 탁트인 바다를 볼 수 있는 뷰도 정말 멋져요./5\n",
      "뷰맛집, 당근케잌맛집, 당근주스는 아주 당근이 녹은것처럼 진한맛이었어요~ 무료엽서 보낼수있게 주신것도 추억이 남을것같아요~/5\n",
      "작년에 이어 올해도 방문! 당근 마카롱 달지않고 맛있고 주스도 맛있어요 커피 볶는 소리와 냄새까지 너무 좋습니다/5\n",
      "아무생각없이 커피가 마시고 싶어 홀로 찾은 카페  커피도 맛있고 엽서 속에 지금 이 순간을 담을 수 있어서 좋았어요  엽서는 나중에 집으로 보내준다고 하니 여행이 끝난 후 시간이 지나 엽서를 받게 되면 또 하나의 행복이 찾아올 것 같습니다 :) /5\n",
      "커피값도 싸지 않은데 알바는 넘 일하기 귀찮아하는것 같네요~/2\n",
      "바다가 보이는 당근케익 맛집! 제주 여행 일주일 동안  두번씩 찾아온 뷰 맛집, 케익 맛집/5\n",
      "뷰는 좋으니 커피맛이 형편없음. 이 정도 맛에 이 가격을 받는다는게 뷰때문에 그런지는 모르겠으나 당근쥬스는 안먹어봤고 암튼 커피 완전 별로임/1\n",
      "경치도 좋고 당근쥬스, 커피맛도 좋아요/5\n",
      "당근주스 맛있어요~ 세화해변 뷰맛집 아기자기 카페 소품도 많아서 사진찍기 좋아요/5\n",
      "뷰 예쁘고 음료도 예쁘고 맛있어요! 또 오고 싶은 카페/5\n",
      "경치도 좋고 당근주스랑 당근케잌도 맛있습니다. 다음에 또 올래요~^^/5\n",
      "당근주스가 진짜 귀여워요♡ 오션뷰도 최고고 인테리어도 좋아요~~/5\n",
      "음료도 맛있었고 테라스에서 먹었는데 뷰가 진짜 좋았어요 엽서 보내는 이벤트같은 것도 있어서 해볼려고 하는데 어떻게 하는 건지 몰라 바쁜 와중에도 여직원분한테 여쭤보니 정말 친절하게 가르쳐주셔서 좋았어요!! 덕분에 친구랑 좋은 추억 만들었어요 감사합니다❤/5\n",
      "분위기도 좋고 우표 부칠 수 있는 점이 너무 좋은것 같아요 !!/5\n",
      "카페이쁘고 우체국 갬성있네요 당근주스도 맛있어요 근데 여자직원분 말투,표정이 사람을 불편하게 만드네요.. 남자분은 친절하신데../3\n",
      "오션뷰, 맛있는 음료와 케이크! 특색있는 엽서까지 너무 좋은 세화카페 :)))/5\n",
      "카페 라라라! 매년 오는 곳이지만 뷰도 좋고 당근쥬스도 너무 맛있습니다!/5\n",
      "당근 케이크 너무 맛있게 먹었어요! 엽서도 넘 이뻐요 :) /5\n",
      "뷰도 맛도 좋은 곳!친절하시고 카페 자체도 예뻐서 기분이 좋았어요!/5\n",
      "세화해변 올 때마다 들려용~! 바다를 바라보며 주신 엽서에 편지도 쓰고 그림도 그리면서 커피 한잔의 여유!! 이게 바로 힐링이에요ㅠㅠ♡/5\n",
      "색연필과 엽서 덕분에 여행의 여유를 찾음 여행 바쁠필요없는데/5\n",
      "뷰맛집에 커피맛집에 편지까지 보내주는 메신저 카페에요! 제주 여행 마지막날 아주 옴팡지게 추억 남겨두고 갑니다. 다음에 올때 또 세화로 오려구요 너무 이뻐요/5\n",
      "최고의 장소  여유는 여기서 즐기는거/5\n",
      "넘 깔끔하고 예쁜 세화 대표 커피숍!  당근쥬스 넘넘 맛있어용 !!!/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b851284fa40a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b851284fa40a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#####\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b851284fa40a>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(place)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# 검색된 첫 페이지 장소 목록 크롤링하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mcrawling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplace_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0msearch_area\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b851284fa40a>\u001b[0m in \u001b[0;36mcrawling\u001b[0;34m(place, place_lists)\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m')'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                     \u001b[0mextract_review\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplace_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                     \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_link_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'다음'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 10페이지 이상으로 넘어가기 위한 다음 버튼 클릭\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b851284fa40a>\u001b[0m in \u001b[0;36mextract_review\u001b[0;34m(place_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# 첫 페이지 리뷰 목록 찾기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m        \u001b[0;31m# It's a file-type object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         elif len(markup) <= 256 and (\n\u001b[0m\u001b[1;32m    311\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34mb'<'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'<'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "##############################################################  ############\n",
    "##################### variable related selenium ##########################\n",
    "##########################################################################\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('lang=ko_KR')\n",
    "chromedriver_path = \"chromedriver\"\n",
    "driver = webdriver.Chrome()  # chromedriver 열기\n",
    "\n",
    "\n",
    "def main():\n",
    "    global driver, load_wb, review_num\n",
    "\n",
    "    driver.implicitly_wait(4)  # 렌더링 될때까지 기다린다 4초\n",
    "    driver.get('https://map.kakao.com/')  # 주소 가져오기\n",
    "\n",
    "    # 검색할 목록\n",
    "    place_infos = ['제주 맛집']\n",
    "\n",
    "    for i, place in enumerate(place_infos):\n",
    "        # delay\n",
    "        if i % 4 == 0 and i != 0:\n",
    "            sleep(5)\n",
    "        print(\"#####\", i)\n",
    "        search(place)\n",
    "\n",
    "    driver.quit()\n",
    "    print(\"finish\")\n",
    "def search(place):\n",
    "    global driver\n",
    "\n",
    "    search_area = driver.find_element_by_xpath('//*[@id=\"search.keyword.query\"]')  # 검색 창\n",
    "    search_area.send_keys(place)  # 검색어 입력\n",
    "    driver.find_element_by_xpath('//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
    "    sleep(1)\n",
    "\n",
    "    # 검색된 정보가 있는 경우에만 탐색\n",
    "    # 1번 페이지 place list 읽기\n",
    "    html = driver.page_source\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    place_lists = soup.select('.placelist > .PlaceItem') # 검색된 장소 목록\n",
    "\n",
    "    # 검색된 첫 페이지 장소 목록 크롤링하기\n",
    "    crawling(place, place_lists)\n",
    "    search_area.clear()\n",
    "\n",
    "    # 우선 더보기 클릭해서 2페이지\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"info.search.place.more\"]').send_keys(Keys.ENTER)\n",
    "        sleep(1)\n",
    "\n",
    "        # 2~ 5페이지 읽기\n",
    "        for i in range(2, 6):\n",
    "            # 페이지 넘기기\n",
    "            xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
    "            driver.find_element_by_xpath(xPath).send_keys(Keys.ENTER)\n",
    "            sleep(1)\n",
    "\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            place_lists = soup.select('.placelist > .PlaceItem') # 장소 목록 list\n",
    "\n",
    "            crawling(place, place_lists)\n",
    "\n",
    "    except ElementNotInteractableException:\n",
    "        print('not found')\n",
    "    finally:\n",
    "        search_area.clear()\n",
    "def crawling(place, place_lists):\n",
    "    \"\"\"\n",
    "    페이지 목록을 받아서 크롤링 하는 함수\n",
    "    :param place: 리뷰 정보 찾을 장소이름\n",
    "    \"\"\"\n",
    "\n",
    "    while_flag = False\n",
    "    for i, place in enumerate(place_lists):\n",
    "        # 광고에 따라서 index 조정해야함\n",
    "        if i >= 6:\n",
    "            i += 1\n",
    "\n",
    "        place_name = place.select('.head_item > .tit_name > .link_name')[0].text  # place name\n",
    "        place_address = place.select('.info_item > .addr > p')[0].text  # place address\n",
    "\n",
    "        detail_page_xpath = '//*[@id=\"info.search.place.list\"]/li[' + str(i + 1) + ']/div[5]/div[4]/a[1]'\n",
    "        driver.find_element_by_xpath(detail_page_xpath).send_keys(Keys.ENTER)\n",
    "        driver.switch_to.window(driver.window_handles[-1])  # 상세정보 탭으로 변환\n",
    "        sleep(1)\n",
    "\n",
    "        print('####', place_name)\n",
    "\n",
    "        # 첫 페이지\n",
    "        extract_review(place_name)\n",
    "\n",
    "        # 2-5 페이지\n",
    "        idx = 3\n",
    "        try:\n",
    "            page_num = len(driver.find_elements_by_class_name('link_page')) # 페이지 수 찾기\n",
    "            for i in range(page_num-1):\n",
    "                # css selector를 이용해 페이지 버튼 누르기\n",
    "                driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                sleep(1)\n",
    "                extract_review(place_name)\n",
    "                idx += 1\n",
    "            driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 5페이지가 넘는 경우 다음 버튼 누르기\n",
    "            sleep(1)\n",
    "            extract_review(place_name) # 리뷰 추출\n",
    "        except (NoSuchElementException, ElementNotInteractableException):\n",
    "            print(\"no review in crawling\")\n",
    "\n",
    "        # 그 이후 페이지\n",
    "        while True:\n",
    "            idx = 4\n",
    "            try:\n",
    "                page_num = len(driver.find_elements_by_class_name('link_page'))\n",
    "                for i in range(page_num-1):\n",
    "                    driver.find_element_by_css_selector('#mArticle > div.cont_evaluation > div.evaluation_review > div > a:nth-child(' + str(idx) +')').send_keys(Keys.ENTER)\n",
    "                    sleep(1)\n",
    "                    extract_review(place_name)\n",
    "                    idx += 1\n",
    "                driver.find_element_by_link_text('다음').send_keys(Keys.ENTER) # 10페이지 이상으로 넘어가기 위한 다음 버튼 클릭\n",
    "                sleep(1)\n",
    "                extract_review(place_name) # 리뷰 추출\n",
    "            except (NoSuchElementException, ElementNotInteractableException):\n",
    "                print(\"no review in crawling\")\n",
    "                break\n",
    "\n",
    "        driver.close()\n",
    "        driver.switch_to.window(driver.window_handles[0])  # 검색 탭으로 전환\n",
    "def extract_review(place_name):\n",
    "    global driver\n",
    "\n",
    "    ret = True\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # 첫 페이지 리뷰 목록 찾기\n",
    "    review_lists = soup.select('.list_evaluation > li')\n",
    "\n",
    "    # 리뷰가 있는 경우\n",
    "    if len(review_lists) != 0:\n",
    "        for i, review in enumerate(review_lists):\n",
    "            comment = review.select('.txt_comment > span') # 리뷰\n",
    "            rating = review.select('.grade_star > em') # 별점\n",
    "            val = ''\n",
    "            if len(comment) != 0:\n",
    "                if len(rating) != 0:\n",
    "                    val = comment[0].text + '/' + rating[0].text.replace('점', '')\n",
    "                else:\n",
    "                    val = comment[0].text + '/0'\n",
    "                print(val)\n",
    "\n",
    "    else:\n",
    "        print('no review in extract')\n",
    "        ret = False\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
